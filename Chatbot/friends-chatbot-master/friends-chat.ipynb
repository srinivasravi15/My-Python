{
 "metadata": {
  "name": "",
  "signature": "sha256:ae78d4845dce8ea52c0d1498f490f84581df4c8362a62416140c6c0702ea4d53"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sys\n",
      "import nltk\n",
      "import pyprind\n",
      "from nltk.corpus import wordnet as wn\n",
      "from sklearn.metrics.pairwise import cosine_similarity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('data/friends-final.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_triturns(data):\n",
      "    L = []\n",
      "    for i, row in data.iterrows():\n",
      "        if i+2 < data.shape[0]:\n",
      "            if row['person'] == data.irow(i+2)['person'] and row['person'] != data.irow(i+1)['person']:\n",
      "                L.append(i)\n",
      "    return L\n",
      "triturns = joblib.load('blobs/triturns.pkl') #get_triturns(data)\n",
      "print len(triturns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "35572\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SYNSETS = {}\n",
      "all_tags = ['CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD',\n",
      "       'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB',\n",
      "       'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN',\n",
      "       'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n",
      "\n",
      "def get_synsets(text):\n",
      "    if not text in SYNSETS:\n",
      "        sent = nltk.pos_tag(nltk.word_tokenize(text))\n",
      "        chunks = nltk.ne_chunk(sent, binary=False)\n",
      "        s = set()\n",
      "        def add_synsets(synsets):\n",
      "            for synset in synsets:\n",
      "                s.add(synset)\n",
      "        #print \"SENT: \", text\n",
      "        for c in chunks:\n",
      "            if hasattr(c, 'node'):\n",
      "                if c.node == 'PERSON':\n",
      "                    add_synsets(wn.synsets('person', pos=wn.NOUN))\n",
      "                elif c.node == 'ORGANIZATION':\n",
      "                    add_synsets(wn.synsets('organization', pos=wn.NOUN))                \n",
      "                elif c.node == 'GPE':\n",
      "                    add_synsets(wn.synsets('place', pos=wn.NOUN))\n",
      "                elif c.node == 'LOCATION':\n",
      "                    add_synsets(wn.synsets('location', pos=wn.NOUN))\n",
      "                elif c.node == 'FACILITY':\n",
      "                    add_synsets(wn.synsets('facility', pos=wn.NOUN))\n",
      "                elif c.node == 'GSP':\n",
      "                    add_synsets(wn.synsets('group', pos=wn.NOUN))                \n",
      "                else:\n",
      "                    print c, c.node, c.leaves()\n",
      "            elif c[1][:2] in ['VB', 'JJ', 'ADV', 'NN']:\n",
      "                pos = {'VB': wn.VERB, 'NN': wn.NOUN, 'ADV': wn.ADV, 'JJ': wn.ADJ}[c[1][:2]]\n",
      "                add_synsets(wn.synsets(c[0], pos=pos))\n",
      "            else:\n",
      "                add_synsets(wn.synsets(c[0]))\n",
      "        SYNSETS[text] = set([x.name for x in s])\n",
      "    return SYNSETS[text]\n",
      "\n",
      "def sem_sim(s1, s2):\n",
      "    ss1 = get_synsets(s1)\n",
      "    ss2 = get_synsets(s2)\n",
      "    if ss1 == ss2:\n",
      "        return 1\n",
      "    return 2*len(ss1.intersection(ss2)) / (len(ss1) + len(ss2))\n",
      "\n",
      "\n",
      "def cos_sim(s1, s2):\n",
      "    d = [{}, {}]\n",
      "    for p in all_tags:\n",
      "        #pass\n",
      "        d[0][p] = d[1][p] = 0\n",
      "    for i,s in enumerate([s1, s2]):\n",
      "        tags = nltk.pos_tag(nltk.word_tokenize(s))\n",
      "        for t in tags:\n",
      "            if t[1] not in d[i]:\n",
      "                pass\n",
      "                #d[i][t[1]] = 0\n",
      "            else:\n",
      "                d[i][t[1]] += 1\n",
      "    return cosine_similarity([d[0][p] for p in all_tags], [d[1][p] for p in all_tags])[0][0]\n",
      "\n",
      "def sim(s1, s2, alpha=0.7):\n",
      "    return alpha*sem_sim(s1, s2) + (1-alpha)*cos_sim(s1, s2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_synsets():\n",
      "    if True:\n",
      "        return joblib.load('blobs/SYNSETS.pkl')\n",
      "    for i,tt in enumerate(triturns):\n",
      "        if i % 100 == 0:\n",
      "            print i\n",
      "        get_synsets(data.irow(tt)['line'])\n",
      "        get_synsets(data.irow(tt+1)['line'])\n",
      "        get_synsets(data.irow(tt+2)['line'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SYNSETS = joblib.load('blobs/SYNSETS.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filter_triturns(thresh=0.7):\n",
      "    L = []\n",
      "    bar = pyprind.ProgBar(len(triturns), monitor=True)\n",
      "    for i,tt in enumerate(triturns):\n",
      "        a = data.irow(tt)['line']\n",
      "        b = data.irow(tt+1)['line']\n",
      "        c = data.irow(tt+2)['line']\n",
      "        if sem_sim(a, b) > thresh:\n",
      "            L.append([a,b])\n",
      "        if sem_sim(b, c) > thresh:\n",
      "            L.append([b,c])\n",
      "        bar.update()\n",
      "    return list(set(L))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filtered_triturns = filter_triturns(0.66)\n",
      "print len(filtered_triturns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "joblib.dump(filtered_triturns, 'blobs/filtered_triturns.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 238,
       "text": [
        "['filtered_triturns.pkl']"
       ]
      }
     ],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from StringIO import StringIO\n",
      "str = StringIO(\n",
      "\"\"\"\n",
      "1.\tCC\tCoordinating conjunction\n",
      "2.\tCD\tCardinal number\n",
      "3.\tDT\tDeterminer\n",
      "4.\tEX\tExistential there\n",
      "5.\tFW\tForeign word\n",
      "6.\tIN\tPreposition or subordinating conjunction\n",
      "7.\tJJ\tAdjective\n",
      "8.\tJJR\tAdjective, comparative\n",
      "9.\tJJS\tAdjective, superlative\n",
      "10.\tLS\tList item marker\n",
      "11.\tMD\tModal\n",
      "12.\tNN\tNoun, singular or mass\n",
      "13.\tNNS\tNoun, plural\n",
      "14.\tNNP\tProper noun, singular\n",
      "15.\tNNPS\tProper noun, plural\n",
      "16.\tPDT\tPredeterminer\n",
      "17.\tPOS\tPossessive ending\n",
      "18.\tPRP\tPersonal pronoun\n",
      "19.\tPRP$\tPossessive pronoun\n",
      "20.\tRB\tAdverb\n",
      "21.\tRBR\tAdverb, comparative\n",
      "22.\tRBS\tAdverb, superlative\n",
      "23.\tRP\tParticle\n",
      "24.\tSYM\tSymbol\n",
      "25.\tTO\tto\n",
      "26.\tUH\tInterjection\n",
      "27.\tVB\tVerb, base form\n",
      "28.\tVBD\tVerb, past tense\n",
      "29.\tVBG\tVerb, gerund or present participle\n",
      "30.\tVBN\tVerb, past participle\n",
      "31.\tVBP\tVerb, non-3rd person singular present\n",
      "32.\tVBZ\tVerb, 3rd person singular present\n",
      "33.\tWDT\tWh-determiner\n",
      "34.\tWP\tWh-pronoun\n",
      "35.\tWP$\tPossessive wh-pronoun\n",
      "36.\tWRB\tWh-adverb\n",
      "\"\"\"\n",
      ")\n",
      "df = pd.DataFrame.from_csv(str, sep='\t', header=None)\n",
      "all_tags = df[1].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}